This application converts spoken descriptions into AI-generated images with automatic captions. It uses state-of-the-art AI models for speech recognition, image generation, and image captioning, while storing the results in both a PostgreSQL database and DigitalOcean Spaces.

## Features

- üé§ **Speech-to-Text**: Uses OpenAI's Whisper model for accurate speech recognition
- üé® **Image Generation**: Generates images from text using Flux Schnell model
- üìù **Image Captioning**: Automatically generates image descriptions using BLIP model
- üóÑÔ∏è **Storage Solutions**: 
  - Images stored in DigitalOcean Spaces
  - Metadata stored in PostgreSQL database
- üåê **Modern UI**: Built with Gradio for a clean, user-friendly interface

## Prerequisites

- Python 3.8+
- PostgreSQL database
- DigitalOcean Spaces account
- Replicate API key
- Docker and Docker Compose (for containerized deployment)

## Installation

### Option 1: Local Installation

1. Clone the repository:
```bash
git clone https://github.com/hivenetes/distributed-multi-modal-agentic-ai.git
cd distributed-multi-modal-agentic-ai
```

2. Install required packages:
```bash
pip install -r requirements.txt
```

3. Copy `.env.example` and create a `.env` file in the project root with the following variables:
```env
# Database Configuration
DB_USER=your_db_user
DB_PASSWORD=your_db_password
DB_HOST=your_db_host
DB_PORT=5432
DB_NAME=your_db_name

# DigitalOcean Spaces Configuration
SPACES_KEY=your_spaces_key
SPACES_SECRET=your_spaces_secret
SPACES_REGION=your_spaces_region
SPACES_ENDPOINT=your_spaces_endpoint
SPACES_BUCKET=your_bucket_name

# Replicate API Configuration
REPLICATE_API_TOKEN=your_replicate_api_token
```

### Option 2: Docker Installation

1. Clone the repository:
```bash
git clone https://github.com/hivenetes/distributed-multi-modal-agentic-ai.git
cd distributed-multi-modal-agentic-ai
```

2. Copy `.env.example` and create a `.env` file as described above.

3. Build and run the containers:
```bash
docker compose up --build
```

The application will be available at http://localhost:7860

## Project Structure

```
distributed-multi-modal-agentic-ai/
‚îú‚îÄ‚îÄ app.py              # Main application file
‚îú‚îÄ‚îÄ db_config.py        # Database configuration and models
‚îú‚îÄ‚îÄ requirements.txt    # Project dependencies
‚îú‚îÄ‚îÄ Dockerfile         # Docker configuration
‚îú‚îÄ‚îÄ docker-compose.yml # Docker Compose configuration
‚îú‚îÄ‚îÄ images/            # Local image storage
‚îî‚îÄ‚îÄ README.md          # This file
```

## Usage

1. Start the application:
```bash
python app.py
```

2. Open your web browser and navigate to the provided URL (typically http://localhost:7860)

3. Use the interface to:
   - Record audio describing the image you want to generate
   - Click "Submit" to transcribe the audio
   - Click "Generate Image" to create the image
   - Click "Generate Caption" to get an AI-generated description
   - Click "Store Image and Caption" to save everything to the database and cloud storage

## Technical Details

- **Speech Recognition**: Uses OpenAI's Whisper model via the Transformers library
- **Image Generation**: Uses Flux Schnell model via Replicate API
- **Image Captioning**: Uses BLIP model for generating image descriptions
- **Database**: PostgreSQL with SQLAlchemy ORM
- **Cloud Storage**: DigitalOcean Spaces (S3-compatible)
- **Frontend**: Gradio Blocks interface

## Database Schema

The `image_records` table stores:
- `id`: Primary key
- `prompt`: Original text prompt
- `image_filename`: Name of the stored image file
- `description`: AI-generated image caption
- `created_at`: Timestamp of record creation

## Error Handling

The application includes comprehensive error handling for:
- Audio recording/transcription issues
- Image generation failures
- Database connection problems
- Storage upload errors

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## License

[MIT License](LICENSE) 